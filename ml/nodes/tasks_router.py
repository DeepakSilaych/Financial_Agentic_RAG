from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field

import state
import config
from llm import llm
from utils import log_message


class Task_Question(BaseModel):
    """Draft a refined query and determine routing."""

    task: str = Field(
        description="Task given within the prompt."
    )
    question: str = Field(
        description="Question within the prompt."
    )

_system_prompt = """
You are a helpful financial assistant. You have been asked to assist a user with any prompt they provide.
You will be given the prompt and you will have to extract the task and question from inside it. You will then have to decide whether to trigger the RAG pipeline or directly answer the user's query based on the conversation history and the refined query. Both can be chosen as well.
You are a part of a system like Google Assistant, the system should answer questions as accurately as possible as well as perform tasks as requested.

Example prompt:
1. Add the google revenue stats of 2021 to the spreadsheet I made last week.
Task: Add the data to the spreadsheet which was made last week.
Question: What are the google revenue stats of 2021?

2. Summarize the report I made last night.
Task: Summarize the report made last night.
Question: None

3. What was Apple's core business and corresponding revenue in 2020 and how were they affected by the pandemic?
Task: None
Question: What was Apple's core business and corresponding revenue in 2020 and how were they affected by the pandemic?

The above examples are just for reference. The task and question can be extracted from the prompt in any format.
However, you should return "None" for the task if the prompt is a question and vice versa.
"""


decision_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", _system_prompt),
        (
            "human",
            "Here is the original prompt: {question}",
        ),
    ]
)

task_question = decision_prompt | llm.with_structured_output(Task_Question)


def make_task_question(state: state.OverallState):
    log_message("---EXTRACTING TASK AND QUESTION---")
    query = state["question"]
    
    task_question_output = task_question.invoke({"question": query})
        
    return {
        "task": task_question_output.task,
        "question_in_query": task_question_output.question
    }
    
    
class Task_Question_Combiner(BaseModel):
    """Writes code which completely satisfies the user's prompt."""
    
    code: str = Field(
        "Python code that combines the task and question."
    )

combine_task_question_system_prompt = """
You are a part of a system like Google Assistant, the system should answer questions as accurately as possible as well as perform tasks as requested. You are the last node in the task and question processing pipeline. Task has been performed and the question has been answered. You have to combine the task and question. You output python code that combines the task and question.

Let's say the task is "Add the data to the spreadsheet which was made last week." and the question is "What are the google revenue stats of 2021?". Original prompt: "Add the google revenue stats of 2021 to the spreadsheet I made last week."
Your code should:
1. Combine the task and question.
2. Return the combined task and question.
3. Able to complete the task successfully.

You will be given the code to do the task with gaps for the question. You have to complete the code as well as proofread it. The final code should be able to complete the prompt the user requested.

The input provided to you is:
Task: The original task. Followed by code or instructions to complete the task.
Question: The original question. Followed by answer generated by the previous nodes.
Original_prompt: The original prompt.

"""

combine_task_question_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", combine_task_question_system_prompt),
        (
            "human",
            "Task: {task}\nQuestion: {question}\nOriginal_prompt: {original_prompt}"
        ),
    ]
)

    
def combine_task_question(state: state.OverallState):
    log_message("---COMBINING TASK AND QUESTION---")
    task = state["task"]
    question = state["question_in_query"]
    final_answer = state["final_answer"]
    
    print("Inside combine_task_question")
    if task == "None" and question == "None":
        return state
    elif question == "None":
        code = state["code"]
    else:
        code = combine_task_question_prompt.invoke({
            "task": task + "\n" + code,
            "question": question + "\n" + final_answer,
            "original_prompt": state["question"]
        })["code"]
    
    # Write code to a python file
    with open("combined_task_question.py", "w") as file:
        file.write(code)

    try:
        # Execute the python file
        exec(open("combined_task_question.py").read())
    except Exception as e:
        print(e)
        log_message("Error in executing the code.")
        
    
    return {
        "task": task,
        "question": question,
        "code": code
    }