from typing import List, Optional, Dict
from pydantic import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage
import state
from llm import llm

### Nodes for all persona based functionalities
# 1. Create Personas
# 2. Supervisor for centralised
# 3. Decomposer for parallel
# [Old Code]. Persona without tool access for centralised, SWARM
# 5. Persona with tool access for centralised and parallel setting (should be the same)
###

### TODO: 1. the prompts require more engineering
###       2. Persona based retrieval require separate prompts. Vary the type of prompts!
###       3. Verify the output of all functions, to be done in workflow as well.
###       4. Interfacing required for tools


# -1: Answer combiner:
class ConclusiveAnswer(BaseModel):
    answer: str = Field(
        description="Final answer based on individual analyses of the personas."
    )


## TODO: Deal with Citations
## TODO: Should analyst detail be also given to the combiner?
_conclusion_prompt = """You are an expert agent tasked with combining the results of multiple financial analysts to answer the following question:
{question}

Each analyst has contributed their own data and analyses to answer their part of the question. You are now tasked with combining these analyses to as to comprehensively answer the original question.
"""


def combine_discussion(state: state.OverallState):
    discussion = "\n".join([msg for msg in state["messages"]])
    # state["messages"].clear()
    prompt = _conclusion_prompt.format(question=state["question"])
    structured_prompt = ChatPromptTemplate.from_messages(
        [("system", prompt), ("human", "Analyses: {discussion}")]
    )
    answer_generator = structured_prompt | llm.with_structured_output(ConclusiveAnswer)
    answer = answer_generator.invoke({"discussion": discussion})
    return {"final_answer": answer.answer}


# 0. Interface for Tools
## TODO: Maybe this is not required
# def tool_input(state: state.OverallState):
#     raise NotImplementedError


# def update_conversation_with_tool(state: state.ToolState) -> state.OverallState:
#     """
#     Update conversation with the latest tool output.
#     """
#     tool_query = state["tool_query"]
#     tool_output = state["tool_response"]
#     raise NotImplementedError


# 1. Create Personas
class Perspectives(BaseModel):
    analysts: List[state.Analyst] = Field(
        description="Comprehensive list of analysts with their roles and affiliations.",
    )


## TODO: improve prompt
_create_analyst_prompt = """You are tasked with creating a set of expert analyst personas in order to efficiently and effectively answer a question related to finance. Follow these instructions carefully:

1. First, review the question:
{question}
        
2. The User wants these personas to perform the following types of analysis: {analysis_type}. 

3. Determine the most key themes based upon documents, analysis type required and the question above. The number and specificity of the themes depends on the potential complexity of the question.

4. Pick the AT MOST {max_analysts} themes that are distinct and cover the original question completely. 

5. Assign one analyst to each theme. The analyst is as specialised as mandated by the question and theme."""


def create_persona(state: state.OverallState):
    """Creates Analysts"""
    question = state["question"]
    max_analysts = state["max_analysts"]
    analysis_type = state["user_response_for_analysis"]

    structured_llm = llm.with_structured_output(Perspectives)
    system_message = _create_analyst_prompt.format(
        question=question, max_analysts=max_analysts, analysis_type=analysis_type
    )
    analysts = structured_llm.invoke(
        [SystemMessage(content=system_message)]
        + [HumanMessage(content="Generate the set of analysts.")]
    )
    return {
        "analysts": analysts.analysts,
        "num_discussion": 0,
        "current_analyst": analysts.analysts[
            0
        ],  # starting analyst is picked at "random" . This will be overwritten by supervisor in other impls where needed
    }


## 2. Supervisor for centralised/serial


class SupervisorSerialOutput(BaseModel):
    next_step: str = Field(
        description="The next step in the conversation. If the discussion covers the question completely, choose 'done'. Otherwise, pick the next agent to continue the discussion.",
    )
    supervisor_question: Optional[str] = Field(
        description="A specific question (optional) the supervisor wishes to ask the next_analyst in order to add to the conversation."
    )


_supervisor_prompt = """You are a supervisor for a centralised team of analysts. You have been tasked with overseeing the work of the analysts and ensuring that the team is able to efficiently and effectively answer a question related to finance. Follow these instructions carefully:

Your team consists of the following analysts: 
{analysts}

The User wants these personas to perform the following types of analysis: {analysis_type}, in order to answer the question: {question}.

You are also provided the history of the discussion so far. Based on this information, you must decide the next step in conversation.
If you think that the discussion covers the question completely, you can choose to end the discussion, using "next_step":"done".
Otherwise pick the next agent to continue the discussion, using "next_step":<role-of-the-next-agent>.

Over the entire conversation, an agent may be called multiple times. If required to steer the conversation, you may also ask a specific "supervisor_question" to the next agent. If not, you can leave it blank.
"""


_user_prompt_discussion = """The discussion until now is: \n{discussion}"""


def supervisor_basic(state: state.OverallState):
    """Supervisor for centralised team, does not decide on tool use"""
    question = state["question"]
    analysts = state["analysts"]
    analysis_type = state["user_response_for_analysis"]
    # next_step = "done" # default value
    discussion = "\n".join([msg for msg in state["messages"]])

    system_message = _supervisor_prompt.format(
        question=question,
        analysts=[analyst.persona() for analyst in analysts],
        analysis_type=analysis_type,
    )
    structured_llm = llm.with_structured_output(SupervisorSerialOutput)
    supervisor_output = structured_llm.invoke(
        [SystemMessage(content=system_message)]
        + [
            HumanMessage(
                content=_user_prompt_discussion.format({"discussion": discussion})
            )
        ]  ## TODO @geet . Messages should properly correspond to analysts final response
    )

    return {
        "next_step": supervisor_output.next_step,
        "analyst_question": supervisor_output.analyst_question,
    }  ## TODO: Fix output


class ParallelDecomposerOutput(BaseModel):
    QuestionPairs: Dict[str, str] = Field(
        description="analyst name : task assigned to them"
    )


_parallel_decomposer_prompt = """You are a an expert leading a team of financial analysts, tasked with answering the following question: {question}.

Your team of analysts consists of the following members: {analysts}. The User wants these personas to perform the following types of analysis: {analysis_type}.

Using your expertise, break the question down into smaller tasks and assign each task to an analyst. The number of tasks should be equal to the number of analysts in your team. Each task should be distinct and cover the original question completely.

Provide the task assigned to each analyst in the following format: {analyst_name} : {task}.
"""
## TODO: hack to fix any issues
generalist = state.Analyst(
    role="Generalist Financial Expert",
    affiliation="None",
    specialisation="This agent is an expert at answering any type of financial question that cannot be answered by the other analysts. They are the last resort for the team. They are assigned tasks that are not covered by the other analysts.",
)


def persona_decomposer(state: state.OverallState):
    new_analysts = state["analysts"] + [generalist]

    question = state["question"]
    analysts = state["analysts"]
    analysis_type = state["user_response_for_analysis"]
    # next_step = "done" # default value

    system_message = _parallel_decomposer_prompt.format(
        question=question,
        analysts=[analyst.persona() for analyst in analysts],
        analysis_type=analysis_type,
    )
    structured_llm = llm.with_structured_output(ParallelDecomposerOutput)
    supervisor_output = structured_llm.invoke(
        [SystemMessage(content=system_message)]
        ## TODO @geet . Dekh lo
    )
    return {"analysts": new_analysts, "subtasks": supervisor_output.QuestionPairs}


class PersonaCentralisedResponse(BaseModel):
    # current_analyst: str = Field(description="Role of the current analyst.")
    response: str = Field(
        description="Response provided by current analyst which adds information to the discussion."
    )


_agent_answer_prompt_discussion_swarm = """You are an expert analyst with the following background {goals}.\n
You are part of a discussion about solving a question with these analysts (including yourself): {analyst_info}.\n
The question about which we are discussing is:
{question}

Provide your response in a concise manner (max 1 statement) that continues the discussion with the goal of reaching a conclusive solution to the question.\n
Also output the role of the Next Analyst to whom this conversation should proceed to. Note that any Analyst may be called any number of times till final conclusion reached.\n
You may even ask some query to another analyst if needed (provide his role). As the conversation progress too much, try to arrive at a conslusion and End it.\n
If the discussion has reached to a conclusion that sufficiently responds to the question, the next_analyst should be "None".
"""
_agent_answer_centralised_no_tool = """You are an expert analyst with the following background {goals}.\n

You are tasked with answering the following question:
{question}

Provide your response in a concise manner that comprehensively answers the question.
"""
## With tool
## TODO: add more to prompt
_agent_answer_centralised = """You are an expert analyst with the following background {goals}.\n

You are tasked with answering the following question:
{question}

In order to answer the question, you have access to the following tools: {tools}. In order to call the tool, provide the name of the tool, and the query to be made to the tool. You may keep using the tool repeatedly till you have comprehensively answered the question.

"""


## This function is OLD CODE###
def agent_node_centralised(state: state.OverallState):
    """Node for the Agent to answer"""
    analyst_info = ", ".join(analyst.role for analyst in state["analysts"])
    context = state.get("messages", "<<This is the start of conversation>>")
    retrieved = state.get("analysis_retrieved_context", "None")
    # TODO
    prompt = _agent_answer_centralised_no_tool.format(
        goals=state["analyst"].persona(), question=state["current_task"]
    )
    structured_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", prompt),
            (
                "human",
                "Relevant Information fetched:{retrieved} \n\n Discussion till now is: {context}",
            ),
        ]
    )
    # TODO
    agent_answer_generator = structured_prompt | llm.with_structured_output(
        PersonaCentralisedResponse
    )
    answer = agent_answer_generator.invoke({"context": context, "retrieved": retrieved})
    message = state["current_analyst"].role + ":\n" + answer.response
    return {
        "messages": [message],
        "num_discussion": state["num_discussion"] + 1,
    }


### This function is OLD CODE ###
# def agent_node_swarm(state: state.OverallState):
#     """Node for the Agent to answer"""
#     analyst_info = ", ".join(analyst.role for analyst in state["analysts"])
#     context = state.get("messages", "<<This is the start of conversation>>")
#     retrieved = state.get("analysis_retrieved_context", "None")
# #TODO
#     prompt = .format(
#         goals=state["analyst"], question=state["question"], analyst_info=analyst_info
#     )
#     structured_prompt = ChatPromptTemplate.from_messages(
#         [
#             ("system", prompt),
#             (
#                 "human",
#                 "Relevant Information fetched:{retrieved} \n\n Discussion till now is: {context}",
#             ),
#         ]
#     )
#     agent_answer_generator = structured_prompt | llm.with_structured_output(
#         PersonaSWARMResponse
#     )
#     #TODO
#     answer = agent_answer_generator.invoke({"context": context, "retrieved": retrieved})
#     message = state["current_analyst"].role + ":\n" + answer.response
#     return {
#         "messages": [message],
#         "next_step": answer.next_step,
#         "num_discussion": state["num_discussion"] + 1,
#     }
###


class PersonaCentralisedResponseTool(BaseModel):
    # current_analyst: str = Field(description="Role of the current analyst.")
    next_step: str = Field(
        description="The next step, which may either be the name of the tool, or 'done'"
    )
    question: Optional[str] = Field(
        description="If the next step is a tool use, the input to the tool in the correct format"
    )
    response: str = Field(
        description="Response provided by current analyst which adds information to the discussion. Your response may also be the question to the tool."
    )


class PersonaSWARMResponseTool(BaseModel):
    # current_analyst: str = Field(description="Role of the current analyst.")
    response: str = Field(
        description="Response provided by current analyst which adds to the current discussion."
    )
    next_step: str = Field(
        description="The next step in the conversation. If the discussion covers the question completely, choose 'done'. Otherwise, pick the next agent to continue the discussion.",
    )
    tool_query: Optional[str] = Field(
        description="If the next step corresponds to a tool, provide the input to be given to the tool."
    )


def agent_node_centralised_tooled(state: state.OverallState):
    """Node for the Agent to answer"""
    analyst_info = ", ".join(analyst.role for analyst in state["analysts"])

    context = state.get("messages", "<<This is the start of conversation>>")
    retrieved = state.get("analysis_retrieved_context", "None")
    ## TODO
    prompt = _agent_answer_centralised(
        goals=state["analyst"].persona(),
        question=state["current_task"],
        tools="\n".join([tool.tool_info for tool in state["tools"]]),
    )
    structured_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", prompt),
            (
                "human",
                "Relevant Information fetched:{retrieved} \n\n Discussion till now is: {context}",
            ),
        ]
    )
    agent_answer_generator = structured_prompt | llm.with_structured_output(
        PersonaCentralisedResponseTool
    )
    answer = agent_answer_generator.invoke({"context": context, "retrieved": retrieved})
    message = state["current_analyst"].role + ":\n" + answer.response
    return {
        "messages": [message],
        "next_step": answer.next_step,
        # "num_discussion": state["num_discussion"] + 1,
    }


# def build_agent():
#     def agent_node(state: state.OverallState,):
#         """Node for the Agent to answer"""
#         analyst_info = ", ".join(analyst.role for analyst in state["analysts"])
#         context = state.get("messages", "<<This is the start of conversation>>")
#         retrieved = state.get("analysis_retrieved_context", "None")

#         prompt = _agent_answer_prompt.format(
#             goals=state["analyst"], question=state["question"], analyst_info=analyst_info
#         )
#         structured_prompt = ChatPromptTemplate.from_messages(
#             [
#                 ("system", prompt),
#                 (
#                     "human",
#                     "Relevant Information fetched:{retrieved} \n\n Discussion till now is: {context}",
#                 ),
#             ]
#         )
#         agent_answer_generator = structured_prompt | llm.with_structured_output(
#             AnalystResponse
#         )
#         answer = agent_answer_generator.invoke({"context": context, "retrieved": retrieved})
#         message = state["current_analyst"].role + ":\n" + answer.response
#         return {
#             "messages": [message],
#             "analyst": answer.next_analyst,
#             "num_discussion": state["num_discussion"] + 1,
#         }

#     return agent_node
