from typing import List, Optional

from pydantic import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import AIMessage, RemoveMessage
from utils import log_message
from config import NUM_PREV_MESSAGES
import state
from state import QuestionNode
from llm import llm
from retriever import cache_retreiver


def get_questions_and_answers_by_layer(
    root: QuestionNode, target_layer: int
) -> List[QuestionNode]:
    result = {}

    # If the current node is at the target layer, add its question and answer
    if root.layer == target_layer:
        result[root.question] = root.answer

    # Recursively search in children
    for child in root.children:
        result.update(get_questions_and_answers_by_layer(child, target_layer))

    return result


class DecomposedQuestions(BaseModel):
    """The structure for decomposed question generated by the decomposing the original question."""

    decomposed_questions: List[str] = Field(
        description="Contains the subquestions that have been generated by decomposing the original question."
    )


_decomposer_system_prompt = """I'm going to ask you a question. I want you to decompose it into a series of subquestions. Each subquestion should be self-contained with all the information necessary to solve it.

Make sure not to decompose more than necessary or have any trivial subquestions - you'll be evaluated on the simplicity, conciseness, and correctness of your decompositions."""

question_decomposition_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", _decomposer_system_prompt),
        ("human", "Question: {question}"),
    ]
)
question_decomposer = question_decomposition_prompt | llm.with_structured_output(
    DecomposedQuestions
)


def decompose_question(state: state.OverallState):
    """
    Decompose the user question into a series of subquestions to optimize document retrieval.
    """
    log_message("---DECOMPOSE QUESTION---")

    question = state["question"]

    decomposed_questions = question_decomposer.invoke({"question": question})
    decomposed_questions = decomposed_questions.decomposed_questions

    log_message(f"Decomposed questions: {decomposed_questions}")

    return {"decomposed_questions": decomposed_questions}


class DecomposedQuestionGroups(BaseModel):
    """The structure for decomposed question generated by the decomposing the original question."""

    decomposed_question_groups: List[List[str]] = Field(
        description="Contains the groups of subquestions that have been generated by decomposing the original question."
    )


# Prompt for generator critic
"""
I'm going to ask you a question. I want you to break it down into groups of **mutually exclusive and independent sub-questions**.

### Key Requirements:
1. **Mutual Exclusivity**: Ensure each sub-question focuses on a single company and a single year.
2. **Independence**: Sub-questions within the same group should build progressively and logically on earlier answers, but avoid dependencies across different groups.
3. **Self-Containment**: Each group should focus on one specific subtopic or step required to solve the larger question. Avoid overlapping scope between groups or questions.

### Additional Guidelines:
- **Simplicity and Necessity**: Decompose the query only if it is complex or involves multiple companies, years, or subtopics. If the query is simple, return it as is.
- **Avoid Redundancy**: Do not create trivial or overlapping sub-questions.
- **Avoid Definitions**: Do not ask for the meanings of terms or definitions.
- **Single-Year Rule**: If the question spans multiple years or ranges, decompose it into questions such that each sub-question focuses on only one year.

### Examples of Expected Behavior:
1. **Example Query 1:** "What is Apple Inc.'s fiscal year-end date?"
   - **Decomposed Result:** [["What is Apple Inc.'s fiscal year-end date?"]]

2. **Example Query 2:** "In which segments do both Alphabet and Apple generate significant revenue outside of hardware sales in 2021 and 2022?"
   - **Decomposed Result:** 
     [["Which segments did Alphabet generate significant revenue in during 2021?", "Which of these were outside hardware sales?"],
      ["Which segments did Alphabet generate significant revenue in during 2022?", "Which of these were outside hardware sales?"],
      ["Which segments did Apple generate significant revenue in during 2021?", "Which of these were outside hardware sales?"],
      ["Which segments did Apple generate significant revenue in during 2022?", "Which of these were outside hardware sales?"]]

3. **Example Query 3:** "What were Tesla's and GM's operating margins for the years 2020 and 2021, and how do they compare?"
   - **Decomposed Result:**
     [["What was Tesla's operating margin in 2020?"],
      ["What was Tesla's operating margin in 2021?"],
      ["What was GM's operating margin in 2020?"],
      ["What was GM's operating margin in 2021?"],
      ["How do Tesla's and GM's operating margins compare in 2020?"],
      ["How do Tesla's and GM's operating margins compare in 2021?"]]

### Goals:
- Ensure sub-questions are concise, focused, and actionable.
- Decompositions should allow the solution to be built progressively, without unnecessary complexity.
- Make sure each sub-question corresponds to a single company and a single year, as required.
"""

_decomposer_system_prompt_v2 = """I'm going to ask you a question. I want you to break it down into groups of sequential sub-questions.
Each group should be self-contained, focusing on a specific subtopic or step-by-step component necessary for solving the larger question.
Within each group, arrange the questions in a sequence such that each question logically depends on the answers from the previous questions.
Aim for a clear flow in each group, allowing the solution to build progressively from start to finish.
Don't create questions which are asking for definitions or meanings.

It is not necessary to decompose a question if it is simple.
Make sure not to decompose more than necessary or have any trivial subquestions - you'll be evaluated on the simplicity, conciseness, and correctness of your decompositions.
Each of the decomposed question should be dealing in only a single year, if a question is dealing with different years or ranges, decompose it so that every parallel decomposed question has only a single year.
Here are some examples:
1. "What is Apple Inc.'s fiscal year-end date?" => [["What is Apple Inc.'s fiscal year-end date?"]]
2. "In which segments do both Alphabet and Apple generate significant revenue outside of hardware sales?" => [["Which segments does Alphabet generate significant revenue in?", "Which of these is other than hardware sales?"], ["Which segments does Apple generate significant revenue in?", "Which of these is other than hardware sales?"]]
"""

question_decomposition_prompt_v2 = ChatPromptTemplate.from_messages(
    [
        ("system", _decomposer_system_prompt_v2),
        ("human", "Question: {question}"),
    ]
)
question_decomposer_v2 = question_decomposition_prompt_v2 | llm.with_structured_output(
    DecomposedQuestionGroups
)


def decompose_question_v2(state: state.OverallState):
    """
    Decompose the user question into a series of subquestions to optimize document retrieval.
    """
    log_message("---DECOMPOSING QUESTION IN SERIES AND PARALLEL---")

    question = state["question"]

    decomposed_questions_groups = question_decomposer_v2.invoke({"question": question})
    decomposed_questions_groups = decomposed_questions_groups.decomposed_question_groups

    log_message(f"------Decomposed question groups: {decomposed_questions_groups}")

    return {"decomposed_question_groups": decomposed_questions_groups}


###CONTREGEN IMPLEMENTATION

_decomposer_system_prompt_v3 = """
I'm going to ask you a question. I want you to break it down into sequential sub-questions.  
If it is a very complex question, break the question into at most **three broad sub-questions** that work independently to answer the complex question.  

**Split it so that we can further split the new questions in further iterations, unless absolutely not necessary.**  
Aim for a clear flow while breaking the query down, allowing the solution to build progressively from start to finish.  

If the question is simple to answer and does not need more splitting, just return a list with that question in the **exact same wording.**  
Do not decompose more than necessary or create trivial subquestions. Avoid questions that only ask for definitions or meanings.  

Ensure the decomposition is simple, concise, and correct. You will be evaluated on these aspects.  

Here are some examples:  
1. "What is Apple Inc.'s fiscal year-end date?" => ["What is Apple Inc.'s fiscal year-end date?"]  
2. "In which segments do both Alphabet and Apple generate significant revenue outside of hardware sales?" => ["Which segments does Alphabet generate significant revenue in, other than hardware sales?", "Which segments does Apple generate significant revenue in, other than hardware sales?"]  
3. "Which segments does Alphabet generate significant revenue in, other than hardware sales?" => ["Which segments does Alphabet generate significant revenue in?", "Which of these is other than hardware sales?"]  
4. "Compare Apple and Microsoft's growth in revenue over 2019,2020,2021 and 2022" => ["What is Apple's growth in revenue over 2019,2020,2021 and 2022?", "What is Microsoft's growth in revenue over 2019,2020,2021 and 2022?"]  
5. "What is Microsoft's growth in revenue over 2019,2020,2021 and 2022?" => ["What is Microsoft's revenue in 2019?", "What is Microsoft's revenue in 2020?", "What is Microsoft's revenue in 2021?", "What is Microsoft's revenue in 2022?"]  
   *Note: If splitting like this results in more than three subquestions, aim to combine or broaden the questions to reduce the count while preserving clarity.*  
6. "What are Apple's absolute Research and Development expenses for the year 2020?" => ["What are Apple's absolute Research and Development expenses for the year 2020?"]  
"""


question_decomposition_prompt_v3 = ChatPromptTemplate.from_messages(
    [
        ("system", _decomposer_system_prompt_v3),
        ("human", "Question: {question}"),
    ]
)
question_decomposer_v3 = question_decomposition_prompt_v3 | llm.with_structured_output(
    DecomposedQuestions
)

## PROMPT FOR THE REPEATER WORFLOW

_decomposer_system_prompt_v5 = """
You are a question decomposition agent. Your task is to take a complex financial question and break it into a list of simpler questions that can be quickly answered. These simpler questions should focus on gathering the preliminary information required to address the original question or establish the foundational steps for solving it.
The current year is 2024 and you are given the 10-K documents for the companies involved.

Guidelines:

1. Break the original question into manageable parts that are easy to answer. Focus on extracting straightforward facts or basic data.
2. The list of simpler questions does not need to fully address the original question. That can be handled in subsequent steps.
3. If the original question is inherently simple and can be solved in one iteration, break it into the necessary questions to directly answer it.
4. If the original question is complex, focus only on gathering the necessary foundational data or initial components.
5. Strictly limit the number of questions to 5, no more than 5 questions should be output. You will be rewarded for asking lesser but relevant questions.
6. Ensure the simpler questions align with financial concepts, such as comparing company metrics, calculating parameters, or retrieving data.
7. Dont ask for definitions or meanings
8. Every subquestion must explicitly reference the company, entity, or subject it pertains to, avoiding ambiguous or generic phrasing.

Here are some examples

EXAMPLE 1

##INPUT: Question: How has the market share of Amazon and Walmart evolved in the US retail sector over the last five years, and what key factors contributed to these changes?
##OUTPUT: ["What was Amazon’s market share in the US retail sector for each of the last five years?","What was Walmart’s market share in the US retail sector for each of the last five years?","What were Amazon’s annual revenues from retail in the US for the last five years?","What were Walmart’s annual revenues from retail in the US for the last five years?"]

EXAMPLE 2

##INPUT: Question: How do the revenues and net profits of Apple and Microsoft compare over the last three years?
##OUTPUT: ["What were Apple’s annual revenues for the last three years?","What were Microsoft’s annual revenues for the last three years?","What were Apple’s net profits for the last three years?","What were Microsoft’s net profits for the last three years?"]

EXAMPLE 3

##INPUT: How do Alibaba and Amazon compare in terms of revenue growth in their primary markets (China and the US) and emerging markets over the last three years?
##OUTPUT: ["What were Alibaba’s revenues from China for the last three years?","What were Amazon’s revenues from the US for the last three years?","What were Alibaba’s revenues from emerging markets for the last three years?","What were Amazon’s revenues from emerging markets for the last three years?"]

Now do it for this input
"""

question_decomposition_prompt_v5 = ChatPromptTemplate.from_messages(
    [
        ("system", _decomposer_system_prompt_v5),
        ("human", "##INPUT: {question}\n##OUTPUT:"),
    ]
)
question_decomposer_v5 = question_decomposition_prompt_v5 | llm.with_structured_output(
    DecomposedQuestions
)


class SufficientAnswer(BaseModel):
    """Yes or No if the original question based on qa pairs"""

    justification: str = Field(description="Reasoning for why the output was so")
    sufficient_answer: str = Field(
        description="Yes or No if the original question based on qa pairs"
    )


sufficient_answer_prompt_system = """
You are an answer auditing agent. Your task is to assess whether the subquestions and their answers provide information which fully answer the original question

Follow these instructions
1. If the answers fully address every independent part of the question, your output should be 'Yes' with the justification
2. If a significant portion of the original question remains unasked, your output should be 'No' with the justification
3. Keep a strict check when saying 'No': Only say 'No' if there is an important or significant part of the original question that has not been addressed, or cannot be calculated from the previous answers 
4. If the missing information is minor or if the answers can be logically pieced together in later stages of the pipeline (such as comparison or some calculation), output 'Yes'.
5. If the answer to some subquestion indicates lack of knowledge or context, then dont let the absence of answer for that part be the reason for saying 'No' (understand example 4)

Example 1:

##INPUT
Question: How do the profitability and revenue growth rates of Tesla and General Motors compare over the last five years, including the impact of their respective strategies in emerging markets?
What were Tesla’s revenues for the last five years?: Tesla’s revenues were $53 billion in 2022, $70 billion in 2021, and $80 billion in 2020.
What were General Motors’ revenues for the last five years?: General Motors’ revenues were $122 billion in 2022, $130 billion in 2021, and $135 billion in 2020.
What were Tesla’s net profits for the last five years?: Tesla’s net profits were $10 billion in 2022, $8 billion in 2021, and $6 billion in 2020.
What were General Motors’ net profits for the last five years?: General Motors’ net profits were $5 billion in 2022, $6 billion in 2021, and $7 billion in 2020.
##Output: 
"justification": "The subquestions do not address the impact of Tesla and General Motors' strategies in emerging markets, which is a significant part of the original question."
"sufficient_answer": "No"

Example 2:

##INPUT
Question: In fiscal year 2023, what was the net cash provided by operating activities for Electronic Arts (EA)? Additionally, how much did EA spend on research and development in fiscal year 2023 according to their financial 10-K documents and reports
"What was the net cash provided by operating activities for Electronic Arts (EA) in fiscal year 2023?: The net cash provided by operating activities for Electronic Arts (EA) in fiscal year 2023 totaled $1,520 million, which represents an increase from $1,397 million in 2022.",
"What was the total amount spent by Electronic Arts (EA) on research and development in fiscal year 2023?: In fiscal year 2023, Electronic Arts (EA) spent a total of **$2,328 million** on research and development, which represents 31% of their net revenue."
##Output:
"justification" "The first subquestion and answer fully answer about the net cash for operating activites, and the second pair answers about the Research and development expense, hence the original question is answered'
"sufficient_answer": "Yes"

Example 3:

##INPUT
Question: How do the profitability and revenue growth rates of Tesla and General Motors compare over the last five years?
What were Amazon’s revenues for the last five years?: Amazon’s revenues were $469 billion in 2022, $469 billion in 2021, and $386 billion in 2020, $469 billion in 2019, and $386 billion in 2023.
What were Microsoft’s revenues for the last five years?: Microsoft’s revenues were $168 billion in 2022, $168 billion in 2021, and $143 billion in 2020, $469 billion in 2019, and $386 billion in 2023.
##Output:
"justification": "The subquestions provide sufficient data for the revenues of the companies over the last five years. While the question refers to Tesla and General Motors, the provided answers can still be logically used to compare the revenue growth.",
"sufficient_answer": "Yes"

Example 4:

##INPUT
Question: How do the market capitalizations of Meta and Netflix compare as of 2023?
What is Meta’s market capitalization as of 2023?: Meta’s market capitalization is $850 billion in 2023.
What is Netflix’s market capitalization as of 2023?: Netflix’s market capitalization is $220 billion in 2023.
##Output:
"justification": "The subquestions provide the market capitalization of both companies as of 2023, which fully addresses the original question"
"sufficient_answer": "Yes"

Example 5:

##INPUT
Question: What is the debt-to-equity ratio of IBM and Oracle, and how has it changed over the last five years?
What is IBM’s debt-to-equity ratio for the last five years?: IBM’s debt-to-equity ratio was 3.1 in 2021, 3.2 in 2022, and 3.0 in 2023.
What is Oracle’s debt-to-equity ratio for the last five years?: I don’t know.
##OUTPUT:
"justification": "Even though we dont have the ratio for the last five years, all the important questions needed to answer the original question are asked, so there is no need to split further"
"sufficient_answer": "Yes"

You will be getting the Question and Answer now

"""

sufficient_answer_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", sufficient_answer_prompt_system),
        ("human", "##Input:\nQuestion: {question}\n {qa_pairs}\n##Output: "),
    ]
)
check_sufficient = sufficient_answer_prompt | llm.with_structured_output(
    SufficientAnswer
)

_decomposer_system_prompt_v6 = """
You are tasked with generating new, additional questions that help in answering a given original question. You will be provided with the original question and a set of subquetions related to the original question. 
The current year is 2024, and you are given the 10-K documents for the companies involved.
Follow these steps:

1. Based on the provided subquestions, generate additional, new questions that were not directly asked but are necessary and required in answering the original question. Assume that these subquestions are answered completely, and focus on areas for which we dont have information yet 
2. Ensure the newly generated questions are relevant to the original question and designed to further build the information necessary to answer the original question effectively.
3. Never ask the same or similar questions from the set of subquestion pairs given, keep the list to be independent from the questions asked before. Dont ask for the same information through different sources. 
4. Ask exactly for the financial terms mentioned in the original question, unless the other term requires some prior knowledge not available from the previous questions
5. Dont ask irrelevant questions, stick to what the original question needs, and only add questions which havent been asked in the given subquestions. You will be tested for simplicity and ability to be conscise.
6. Take it the subquestions have been answered completely, so dont ask any new questions based on comparing the results of the previous subquestions. Ask completely new subquestions on aspects of the main question which havent been asked yet
7. Never give more than 5 questions, keep a upper bound at 5 questions, but just ask questions that you are sure will be required. You will be rewarded for asking lesser but relevant questions.
8. You will be penalised for extra questions which are either not relevant to the original question, or for which the information is already gotten from other questions
9. Every subquestion must explicitly reference the company, entity, or subject it pertains to, avoiding ambiguous or generic phrasing.

Here are some examples


EXAMPLE 1

##INPUT:
#Question: What was the percentage increase in revenue for Google Cloud and Google Services in Alphabet Inc.'s 2023 financial reports compared to the previous year, and how do these increases impact specific financial metrics such as net income and operating margin, as outlined in their 2023 10-K documents? Please focus solely on Google Cloud and Google Services without comparisons to other segments of Alphabet Inc.
#Subquestions:
What was the revenue for Google Cloud in Alphabet Inc.'s 2022 financial report?
What was the revenue for Google Cloud in Alphabet Inc.'s 2023 financial report?
What was the revenue for Google Services in Alphabet Inc.'s 2022 financial report?
What was the revenue for Google Services in Alphabet Inc.'s 2023 financial report?
What are operating margin figures for Google Cloud and Google Services in the 2023 financial report?

##OUTPUT:
["What was the net income for Google Cloud in 2023?", "What was the net income of Google Cloud in 2022?","What were the operating margin figures for Google Cloud in 2022?","What were the operating margin figures for Google Services in 2022?"]

EXAMPLE 2

##INPUT:
#Question: What was the percentage increase in revenue for Google Cloud and Google Services in Alphabet Inc.'s 2023 financial reports compared to the previous year, and how do these increases impact specific financial metrics such as net income and operating margin, as outlined in their 2023 10-K documents? Please focus solely on Google Cloud and Google Services without comparisons to other segments of Alphabet Inc.
#Subquestions:
What was the revenue for Google Cloud in Alphabet Inc.'s 2022 financial report?
What was the revenue for Google Cloud in Alphabet Inc.'s 2023 financial report?
What was the revenue for Google Services in Alphabet Inc.'s 2022 financial report?
What was the revenue for Google Services in Alphabet Inc.'s 2023 financial report?
What are operating margin figures for Google Cloud and Google Services in the 2023 financial report?

##OUTPUT:
["What was the net income for Google Cloud in 2023?", "What was the net income of Google Cloud in 2022?","What were the operating margin figures for Google Cloud in 2022?","What were the operating margin figures for Google Services in 2022?"]

EXAMPLE 3

##INPUT:
#Question: How do the profitability and revenue growth of Tesla and General Motors compare over the last three years?
#Subquestions:
What were Tesla’s annual revenues for the last three years?
What were General Motors’ annual revenues for the last three years?
What were Tesla’s net profit margins for the last three years?
What were General Motors’ net profit margins for the last three years?

##OUTPUT:
["What were Tesla’s annual operating expenses for the last three years?","What were General Motors’ annual operating expenses for the last three years?"]
"""

question_decomposition_prompt_v6 = ChatPromptTemplate.from_messages(
    [
        ("system", _decomposer_system_prompt_v6),
        ("human", "##INPUT\n#Question: {question}\n#Subquestions: \n{sub_ques}  ##OUTPUT"),
    ]
)
question_decomposer_v6 = question_decomposition_prompt_v6 | llm.with_structured_output(
    DecomposedQuestions
)


# TODO - REMOVE THIS FUNCTION SOON
'''
def decompose_question_v3(state: state.QuestionDecomposer):
    """
    Decompose the user question into a tree based on Contregen paper
    """
    log_message("---DECOMPOSING QUESTION IN TREE FORMART---")

    question = state["question"]
    counter=state['counter']

    decomposed_questions = question_decomposer_v3.invoke({"question": question})
    decomposed_questions = decomposed_questions.decomposed_questions

    counter+=1
    if(len(decomposed_questions)==1 or counter==3):
        decompose_further=False
    else:
        decompose_further=True
    
    collection=state['collection']
    collection.append(question)

    log_message(f"Parent question:{question}\n Decomposed questions: {decomposed_questions}")

    return {"subquestions": decomposed_questions,"decompose_further":decompose_further,"counter":counter,"collection":collection}
'''

### GENERATOR CRITIC SYSTEM

"""



I'm going to ask you a question. I want you to break it down into groups of sequential sub-questions.


Aim for a clear flow in each group, allowing the solution to build progressively from start to finish.
Don't create questions which are asking for definitions or meanings.

It is not necessary to decompose a question if it is simple.
Make sure not to decompose more than necessary or have any trivial subquestions - you'll be evaluated on the simplicity, conciseness, and correctness of your decompositions.
Each of the decomposed question should be dealing in only a single year, if a question is dealing with different years or ranges, decompose it so that every parallel decomposed question has only a single year.

"""


_decomposer_system_prompt_v4 = """
You are a highly skilled financial data expert and an advanced language model agent tasked with decomposing a complex financial question into subquestions. Your goal is to split the original question into **parallel subquestions**, and each parallel subquestion into **sequential subquestions**, to be used in a Retrieval-Augmented Generation (RAG) pipeline.

### Context:
1. The decomposition process works as follows:
   - A **complex question** is split into groups of sequential subquestions, which are independent of each other.
   - Each group should be self-contained, focusing on a specific subtopic or step-by-step component necessary for solving the larger question.
   - Within each group, arrange the questions in a sequence such that each question logically depends on the answers from the previous questions.
   - Each **parallel subquestion** is further broken down into **sequential subquestions** that need to be answered in order.
2. The answers to the **sequential subquestions** for each parallel subquestion will be used along with the original question to get the final answer. **DO NOT create a new parallel subquestion to compare or summarize answers from other parallel subquestions.** Comparisons will be handled in a later stage.
3. Finally, the answers to all **parallel subquestions** are used to answer the **original question**.

### Task Instructions:
1. Analyze the **original question** to understand its intent and scope.
2. If **suggestions** are provided, incorporate them into the decomposition process.
3. Generate the decomposition as a nested list:
   - The outer list contains **parallel subquestions**.
   - Each inner list contains the **sequential subquestions** for one parallel subquestion.
4. If the question is too simple, don't split it.
5. Avoid creating questions that ask for definitions or meanings.

### Input:
**Original Question:** {question}
**Previous Subquestions:** {prev_subquestions}
**Suggestions:** {suggestion}

### Expected Output:
Produce a nested list of subquestions. For example:
- If no suggestions are provided, generate the decomposition based on your understanding of the question.
- If suggestions are provided, incorporate them into the decomposition and mention the changes in your output.

---

### Examples:

#### **Example 1:**
**Original Question:**
"In which segments do both Alphabet and Apple generate significant revenue outside of hardware sales?"

**Previous Subquestions:**
[[]]

**Suggestions:**
""

**Output:**
[["Which segments does Alphabet generate significant revenue in?", "Which of these is other than hardware sales?"], 
 ["Which segments does Apple generate significant revenue in?", "Which of these is other than hardware sales?"]]

---

#### **Example 2:**
**Original Question:**
"How have Tesla and Ford expanded their operations internationally in the last decade?"

**Previous Subquestions:**
[[]]

**Suggestions:**
1. For Tesla:
   - Replace "What are Tesla's international operations?" with "What specific strategies has Tesla used to expand internationally in the last decade?"
2. For Ford:
   - Add "What specific strategies has Ford used to expand internationally in the last decade?"

**Output:**
[["How has Tesla expanded internationally?", "What specific strategies has Tesla used to expand internationally in the last decade?"], 
 ["How has Ford expanded internationally?", "What specific strategies has Ford used to expand internationally in the last decade?"]]

---

#### **Example 3:**
**Original Question:**
"What is Apple's current stock price?"

**Previous Subquestions:**
[[]]

**Suggestions:**
""

**Output:**
["What is Apple's current stock price?"]

---

#### **Example 4:**
**Original Question:**
"What are the total research and development revenues in absolute values for Apple and Google for the years 2022 and 2023, including a comparison between the two companies for each year?"

**Previous Subquestions:**
[
 ["What were Apple's total research and development revenues in absolute values for the year 2022?", 
  "What were Apple's total research and development revenues in absolute values for the year 2023?"],
 ["What were Google's total research and development revenues in absolute values for the year 2022?", 
  "What were Google's total research and development revenues in absolute values for the year 2023?"]
]

**Suggestions:**
""

**Output:**
[
 ["What were Apple's total research and development revenues in absolute values for the year 2022?", 
  "What were Apple's total research and development revenues in absolute values for the year 2023?"],
 ["What were Google's total research and development revenues in absolute values for the year 2022?", 
  "What were Google's total research and development revenues in absolute values for the year 2023?"]
]

"""


question_decomposition_prompt_v4 = ChatPromptTemplate.from_messages(
    [
        ("system", _decomposer_system_prompt_v4),
        (
            "human",
            " Original Question: {question} \n Previous Subquestions: {prev_subquestions} Suggestion: {suggestion} \n Output: \n",
        ),
    ]
)
question_decomposer_v4 = question_decomposition_prompt_v4 | llm.with_structured_output(
    DecomposedQuestionGroups
)


def decompose_question_v4(state: state.OverallState):
    """
    Decompose the user question into a series of subquestions to optimize document retrieval, but taking in suggestions from a critic
    """
    log_message("---DECOMPOSING QUESTION IN SERIES AND PARALLEL---")

    question = state["question"]
    suggestion = state.get("critic_suggestion", "")
    prev_subquestions = state.get("decomposed_question_groups", [[]])

    decomposed_questions_groups = question_decomposer_v4.invoke(
        {
            "question": question,
            "suggestion": suggestion,
            "prev_subquestions": prev_subquestions,
        }
    )
    decomposed_questions_groups = decomposed_questions_groups.decomposed_question_groups

    log_message(f"------Decomposed question groups: {decomposed_questions_groups}")

    return {"decomposed_question_groups": decomposed_questions_groups}


_generator_critic_system = """
You are a highly skilled financial data expert and an advanced language model agent tasked with reviewing the decomposition of a complex financial question into subquestions. Your goal is to evaluate whether the provided subquestions effectively address the original question and provide actionable feedback if any changes are needed.

### Context:
1. The decomposition process works as follows:
   - A **complex question** is split into **parallel subquestions**, which are independent of each other.
   - Each **parallel subquestion** is further broken down into **sequential subquestions** that need to be answered in order.
2. The answers to the **sequential subquestions** for each parallel subquestion will collectively provide the answer to the corresponding parallel subquestion.
3. Finally, the answers to all **parallel subquestions** are used to answer the **original question**.
4. The questions should be as simple and direct as possible so that more documents can be retreived during RAG retrieval

### Task Instructions:
1. Evaluate whether the provided **parallel subquestions** comprehensively address the original question.
2. Assess whether the **sequential subquestions** under each parallel subquestion are well-structured, specific, and logically ordered to fully address their respective parallel subquestion.
3. **DO NOT suggest comparisons or summarizations across parallel subquestions.** Comparisons or summaries will be handled separately after all subquestions are answered.
4. If subquestions are simple but effective and follow a structured sequence, **DONT SUGGEST COMBINING THEM**
5. If a single question deals with multiple years, suggest to split them into single years.
6. Suggest improvements if necessary, or confirm the decomposition is effective by replying "No changes."

### Input:
**Original Question:** 
**Proposed Subquestions:** 

### Expected Output:
Provide clear feedback on whether the subquestions should be changed. For example:
- If no changes are needed:
  "No changes."
- If changes are needed:
  - Specify which subquestions should be modified, added, or removed.
  - Justify your suggestions with a brief explanation.

---

### Examples:

#### **Example 1:**
**Original Question:**
"In which segments do both Alphabet and Apple generate significant revenue outside of hardware sales?"

**Proposed Subquestions:**
[["Which segments does Alphabet generate significant revenue in?", "Which of these is other than hardware sales?"], 
 ["Which segments does Apple generate significant revenue in?", "Which of these is other than hardware sales?"]]

**Output:**
No changes.

---

#### **Example 2:**
**Original Question:**
"What are the total research and development revenues in absolute values for Apple and Google for the years 2022 and 2023, including a comparison between the two companies for each year?"

**Proposed Subquestions:**
[
 ["What were Apple's total research and development revenues in absolute values for the year 2022?", 
  "What were Apple's total research and development revenues in absolute values for the year 2023?"],
 ["What were Google's total research and development revenues in absolute values for the year 2022?", 
  "What were Google's total research and development revenues in absolute values for the year 2023?"]
]

**Output:**
No changes.

---

#### **Example 3:**
**Original Question:**
"How do Tesla and Ford allocate their R&D budgets, and what impact does it have on their electric vehicle sales?"

**Proposed Subquestions:**
[["How does Tesla allocate its R&D budget?", "What is Tesla's impact on electric vehicle sales?"], 
 ["How does Ford allocate its R&D budget?", "What is Ford's electric vehicle market share?"]]

**Output:**
Suggested Changes:
1. For Tesla:
   - Revise "What is Tesla's impact on electric vehicle sales?" to "How has Tesla's R&D budget impacted its electric vehicle sales?"
2. For Ford:
   - Revise "What is Ford's electric vehicle market share?" to "How has Ford's R&D budget impacted its electric vehicle sales?"

---

#### **Example 4:**
**Original Question:**
"What is Apple's current stock price?"

**Proposed Subquestions:**
["What is Apple's current stock price?"]

**Output:**
No changes.

###Example 5:
**Original Question:**
"What are the total R&D revenues in absolute dollar amounts for Google and Apple for the years 2022 and 2023? Please provide the data without any additional context or factors influencing the revenues."

**Proposed Subquestions:**
"decomposed_question_groups": [
    [
      "What were Apple's total R&D revenues in absolute dollar amounts for the years 2022 and 2023?"
    ],
    [
      "What were Google's total R&D revenues in absolute dollar amounts for the years 2022 and 2023?"
    ]
  ]


**Output:**
Suggested Changes:
1. Split the questions in each parallel subquestion to make them year-wise for a sequential flow of answering:
   - Revised Subquestions:
     [
       ["What were Apple's total R&D revenues in absolute dollar amounts for the year 2022?", 
        "What were Apple's total R&D revenues in absolute dollar amounts for the year 2023?"],
       ["What were Google's total R&D revenues in absolute dollar amounts for the year 2022?", 
        "What were Google's total R&D revenues in absolute dollar amounts for the year 2023?"]
     ]
"""

generator_critic_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", _generator_critic_system),
        (
            "human",
            " Original Question: {question} , Proposed Subquestions: {question_groups}",
        ),
    ]
)


class Critic_Suggestion(BaseModel):
    """The structure for suggestion given by the critic after seeing the questions split from the original query."""

    critic_suggestion: str = Field(
        description="The combined question generated from the given question and answer of the previous question."
    )


##Building this for the group of questions, so we need it for that output
generator_critic = generator_critic_prompt | llm.with_structured_output(
    Critic_Suggestion
)


def critic_node(state: state.OverallState):
    """
    Provides a suggestion from the critic based on the split of the
    """
    log_message("---Generator Critic---")

    question = state["question"]
    question_groups = state["decomposed_question_groups"]

    state["critic_counter"] = state.get("critic_counter", 0)
    state["critic_counter"] += 1

    question_groups = "\n".join([str(sublist) for sublist in question_groups])

    suggestion = generator_critic.invoke(
        {"question": question, "question_groups": question_groups}
    )
    suggestion = suggestion.critic_suggestion

    state["critic_suggestion"] = suggestion

    log_message(
        f"------Critic Suggestion: {suggestion}  \n Critic Count: {state['critic_counter']}"
    )

    return state


## QUESTION COMBINED V1


class CombinedQuestion(BaseModel):
    """The structure for combined question generated by the combining the question and answer of the previous question."""

    combined_question: str = Field(
        description="The combined question generated from the given question and answer of the previous question."
    )


_question_combiner_system_prompt = """Combine the follow-up question with the previous answer to generate a new question which is concise that includes all the necessary information to fully answer the follow-up.
Return only the follouw-up or improved question and not the remaining context
Ensure the new question is clear, complete, and captures both the context and details needed to respond effectively.
"""

question_combination_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", _question_combiner_system_prompt),
        (
            "human",
            """Here is the previous question and its answer:
{prev_question}: {prev_answer}

Here is the follow up question question: {next_question}""",
        ),
    ]
)
question_combiner = question_combination_prompt | llm.with_structured_output(
    CombinedQuestion
)
# System prompt for combining questions
_question_combiner_system_prompt = """
Combine the follow-up question with the answers to the child questions to generate a new question that is concise but includes all the necessary information to fully answer the follow-up.
Return only the follow-up or improved question, and not the remaining context.
Ensure the new question is clear, complete, and captures both the context and details needed to respond effectively.
"""

# Modified human prompt to include child questions and answers
question_combination_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", _question_combiner_system_prompt),
        (
            "human",
            """Here are the child questions and their respective answers:
{child_questions_and_answers}

Here is the next question to address:
{next_question}""",
        ),
    ]
)


# Define the `child_questions_and_answers` format in the input
def format_child_questions_and_answers(child_questions, child_answers):
    """
    Formats child questions and answers into a single string.

    :param child_questions: List of child questions.
    :param child_answers: List of corresponding child answers.
    :return: A formatted string combining the questions and answers.
    """
    return "\n".join(
        f"{i+1}. {question}: {answer}"
        for i, (question, answer) in enumerate(zip(child_questions, child_answers))
    )


# Example function to combine questions
def combine_questions(child_questions, child_answers, next_question):
    """
    Combines child questions, answers, and a follow-up question into a new concise question.

    :param child_questions: List of child questions.
    :param child_answers: List of answers corresponding to the child questions.
    :param next_question: The follow-up question for the next step.
    :return: The combined question.
    """
    # Format child questions and answers
    child_qa_formatted = format_child_questions_and_answers(
        child_questions, child_answers
    )

    # Generate the new question
    combined_question_input = {
        "child_questions_and_answers": child_qa_formatted,
        "next_question": next_question,
    }
    combined_question = question_combination_prompt | llm.with_structured_output(
        CombinedQuestion
    )
    return combined_question.invoke(combined_question_input).combined_question


# System prompt for combining answers
_answer_combiner_system_prompt = """
Combine the answers to the child questions with the next question to generate a clear and concise answer.
Ensure the response addresses the next question effectively by synthesizing the provided information.
If the child answer for any question indicates any uncertainity, or 'I dont know', dont let it reflect in the final answer.
Return only the combined answer, without additional context or the original child answers.

"""

# Modified human prompt to include child questions, answers, and the follow-up question
answer_combination_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", _answer_combiner_system_prompt),
        (
            "human",
            """Here are the child questions and their respective answers:
{child_questions_and_answers}

Here is the next question to address:
{next_question}""",
        ),
    ]
)


class CombinedAnswer(BaseModel):
    """The structure for combined answer generated by the combining the answers of the decomposed questions."""

    combined_answer: str = Field(
        description="The combined answer generated from the given set of answers of the decomposed questions."
    )


# Function to combine answers
def combine_answers_v3(child_questions, child_answers, next_question):
    """
    Combines child answers into a single answer that addresses the follow-up question.

    :param child_questions: List of child questions.
    :param child_answers: List of answers corresponding to the child questions.
    :param next_question: The follow-up question for the next step.
    :return: A combined answer.
    """
    # Format child questions and answers
    child_qa_formatted = format_child_questions_and_answers(
        child_questions, child_answers
    )

    # Prepare the input for the prompt
    combined_answer_input = {
        "child_questions_and_answers": child_qa_formatted,
        "next_question": next_question,
    }

    # Invoke the prompt to generate the combined answer
    combined_answer = answer_combination_prompt | llm.with_structured_output(
        CombinedAnswer  # Define this schema as needed
    )
    return combined_answer.invoke(combined_answer_input).combined_answer


_question_combiner_system_prompt_v2 = """Combine the follow-up question and their answers along with the original question to generate a new question that includes all the necessary information to fully answer the follow-up.
Ensure the new question is clear, complete, and captures both the context and details needed to respond effectively.
"""

question_combination_prompt_v2 = ChatPromptTemplate.from_messages(
    [
        ("system", _question_combiner_system_prompt),
        (
            "human",
            """Here are the child questions and their answers:
{child_questions_answers}

Here is the follow-up question:{original_question}""",
        ),
    ]
)
question_combiner_v2 = question_combination_prompt_v2 | llm.with_structured_output(
    CombinedQuestion
)


_answer_combiner_system_prompt = """
You are provided with:

- The original query.
- A set of decomposed subquestions and their respective answers.
You need to perform the following tasks : 
1.⁠ ⁠The key task here is to summarize information from multiple answers that each address a specific aspect of the original question.
2.⁠ ⁠The goal is to combine these answers into a cohesive and comprehensive response that captures the full essence of the original question.
3.⁠ ⁠This requires providing a synthesized response that integrates the collective information while maintaining clarity and coherence.
4.⁠ ⁠Additionally, it is important to highlight any connections or overarching themes that emerge from the combined knowledge.
5.⁠ ⁠Crucially, all relevant citations and sourced mentioned in the decomposed answers must be consolidated and included in the final combined response sequentially along with inline citations.
6.⁠ ⁠The outcome should be a thorough, well-rounded answer that addresses the full scope of the original question, drawing insights from the collective knowledge provided in the decomposed responses.
7.⁠ ⁠The final answer should be structured in a logical flow to provide a complete picture for the user.
"""

answers_combination_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", _answer_combiner_system_prompt),
        (
            "human",
            """Here are the decomposed questions and their answers: {decomposed_qa_pairs}

Here is the original question: {original_question}""",
        ),
    ]
)
answers_combiner = answers_combination_prompt | llm.with_structured_output(
    CombinedAnswer
)

### REPEATER WORKFLOW

##QUESTION COMBINER FOR REPEATER WORKFLOW (V2)
'''
class CombinedQuestion2(BaseModel):
    """The structure for combined question generated by the combining the question and answer of the previous question."""

    combined_question: str = Field(
        description="The combined question generated from the given question and answer of the previous question."
    )
    sufficient: str =Field(
        description="Yes or No based on if the question is sufficiently answered"
    )
'''

# TODO - Put in good few shot examples to diregard questions of that sort
# System prompt for combining questions
_question_combiner_system_prompt_v3 = """
You are an information aggregation agent. Your task is to create one new question based on an original question and a set of subquestions with their answers. This question should target missing information needed to fully answer the original question.

Follow these instructions:
1. Review the original question and the provided subquestions with their answers. Identify any missing pieces of information required to fully address the original question.
2. If a subquestion’s answer explicitly states "I don’t know," "not explicitly stated," or suggests uncertainty or missing data, do not base the new question on this unavailable information.
3. Focus only on what can be addressed using the known or explicitly stated answers.
4. Formulate one new question that covers all the relevant missing aspects of the original question in a concise and precise manner. The new question should encompass all remaining gaps.
5. Ensure the new question is distinct from the provided subquestions and does not duplicate their scope.
6. The new question must align with the original question’s focus and use terminology consistent with it.

Example 1
##INPUT
#Original Question: What is the aggregate market value of both Class A and Class B common stock held by non-affiliates for Nike, Inc. (NKE) as of November 30, 2022, calculated using the average stock price over the past year? Additionally, what is the total number of outstanding shares of both Class A and Class B common stock as of July 12, 2023, including any recent stock splits or corporate actions?
#Subquestions and Answers:
What was the average stock price of Nike, Inc. (NKE) over the year leading up to November 30, 2022?: The average stock price of Nike, Inc. (NKE) over the year leading up to November 30, 2022, was $91.39.
What is the number of Class A common shares held by non-affiliates for Nike, Inc. as of November 30, 2022?: As of November 30, 2022, the number of Class A common shares held by non-affiliates is not explicitly stated.
What is the number of Class B common shares held by non-affiliates for Nike, Inc. as of November 30, 2022?: 170,815,547,402 shares.
What is the total number of outstanding Class A and Class B common shares for Nike, Inc. as of July 12, 2023?: 1.50 billion shares combined.
Were there any stock splits or corporate actions affecting Nike, Inc.'s shares between November 30, 2022, and July 12, 2023?: No significant stock splits or corporate actions occurred during this period.

##OUTPUT: What is the aggregate market value of Class B common shares held by non-affiliates for Nike, Inc. as of November 30, 2022, based on the average stock price of $91.39?

Example 2
##INPUT
#Original Question: What is the debt-to-equity ratio of IBM and Oracle, and how has it changed over the last five years?
#Subquestions and Answers:
What is IBM’s debt-to-equity ratio for the last five years?: IBM’s debt-to-equity ratio was 3.1 in 2021, 3.2 in 2022, and 3.0 in 2023.
What is Oracle’s debt-to-equity ratio for the last five years?: I don’t know.

##OUTPUT: What are the key factors influencing changes in IBM’s debt-to-equity ratio over the last five years, and how might similar factors have impacted Oracle during the same period?

Example 3
##INPUT
#Original Question: How do Tesla's and General Motors' R&D expenditures and net profits compare over the past three years?
#Subquestions and Answers:
What were Tesla’s R&D expenditures over the past three years?: $2.5 billion in 2022, $2.0 billion in 2021, and $1.5 billion in 2020.
What were General Motors’ R&D expenditures over the past three years?: Not context provided.
What were Tesla’s net profits over the past three years?: $12 billion in 2022, $10 billion in 2021, and $8 billion in 2020.
What were General Motors’ net profits over the past three years?: $6 billion in 2022, $5 billion in 2021, and $4 billion in 2020.

##OUTPUT: How do Tesla’s R&D expenditures relate to its net profits over the past three years?

Example 4
##INPUT
#Original Question: What are the total sales figures and profit margins for Amazon’s North America and International segments for the year 2022, and how do they compare to the figures for 2021?
#Subquestions and Answers:
What were the total sales figures for Amazon’s North America segment in 2022?: $316 billion.
What were the total sales figures for Amazon’s North America segment in 2021?: $280 billion.
What were the total sales figures for Amazon’s International segment in 2022?: $118 billion.
What were the total sales figures for Amazon’s International segment in 2021?: Not explicitly available.
What were the profit margins for Amazon’s North America and International segments in 2022?: North America: 7%; International: -2%.

##OUTPUT: What were the year-over-year growth rates in total sales for Amazon’s North America segment, and what were the profit margins for its International segment in 2021?

Do it for these now
"""

# Modified human prompt to include child questions and answers
question_combination_prompt_v3 = ChatPromptTemplate.from_messages(
    [
        ("system", _question_combiner_system_prompt_v3),
        (
            "human",
            """##INPUT
Original Question:{question}
#Subquestions and Answers:
{child_questions_and_answers}

##OUTPUT:""",
        ),
    ]
)

def combine_questions_v3(qa_pairs, question):
    """
    Combines child questions, answers, and a follow-up question into a new concise question.

    :param child_questions: List of child questions.
    :param child_answers: List of answers corresponding to the child questions.
    :param next_question: The follow-up question for the next step.
    :return: The combined question.
    """
    # Format child questions and answers
    
    
    # Generate the new question
    combined_question_input = {
        "question": question,
        "child_questions_and_answers": qa_pairs,
    }
    combined_question = question_combination_prompt_v3 | llm.with_structured_output(
        CombinedQuestion
    )
    return combined_question.invoke(combined_question_input).combined_question


## MAKING ANSWER COMBNINER FOR THE REPEATER WORKFLOW

_answer_combiner_system_prompt2 = """

You are an answering agent tasked with synthesizing a comprehensive and coherent answer to an original question. You will be provided with the original question and a list of subquestions along with their corresponding answers. Your task is to:
1.Use the answers to the subquestions to construct a single, complete, and well-structured answer to the original question.
2.Ensure the final answer is clear, concise, and incorporates all relevant details from the subquestions.
3.If any subquestion's answer is uncertain or incomplete (e.g., "I don’t know"), exclude those parts from the final answer while maintaining coherence.
4.Return only the final synthesized answer to the original question.

Here are some examples

Example 1
##INPUT:
Original Question:  What were the R&D expenditures for Google and Amazon in 2021 and 2022, and how do they compare in terms of percentage growth?

Question Answer Pairs

What were Google’s R&D expenditures in 2021 and 2022?: Google spent $31 billion in 2021 and $35 billion in 2022.
What were Amazon’s R&D expenditures in 2021 and 2022?: Amazon spent $56 billion in 2021 and $64 billion in 2022.
How do their percentage growth rates compare?:Google’s R&D expenditures grew by 12.9%, while Amazon’s grew by 14.3%.

##OUTPUT: In 2021 and 2022, Google’s R&D expenditures grew from $31 billion to $35 billion, representing a 12.9% growth rate. Amazon’s R&D expenditures grew from $56 billion to $64 billion, a 14.3% growth rate. Amazon consistently spent more on R&D than Google during this period.

Example 2 
##INPUT:
Original Question: What are the main contributors to urban air pollution, and how do they vary between developed and developing countries?

Question Answer Pairs

What are the primary sources of air pollution in urban areas?: The primary sources are vehicle emissions, industrial activities, and construction dust.
Do these sources differ between developed and developing countries?: Yes, industrial activities are more prominent in developing countries, while vehicle emissions dominate in developed countries.
What measures are being taken to reduce air pollution globally?: I don’t know.

##OUTPUT: The main contributors to urban air pollution include vehicle emissions, industrial activities, and construction dust. In developing countries, industrial activities are a more prominent source of pollution, while vehicle emissions dominate in developed countries.

Example 3 
##INPUT:
Original Question: How does the debt-to-equity ratio of IBM compare to Oracle over the last five years?

Question Answer Pairs

What is IBM’s debt-to-equity ratio over the last five years?: IBM’s debt-to-equity ratio averaged 3.1 over the last five years.
What is Oracle’s debt-to-equity ratio over the last five years?: Oracle’s debt-to-equity ratio averaged 5.4 over the last five years.
Have their trends been stable or fluctuating?: IBM’s ratio has been stable, while Oracle’s ratio has fluctuated significantly, peaking at 6.2 in 2022.

##OUTPUT: Over the last five years, IBM’s debt-to-equity ratio averaged 3.1 and remained stable, while Oracle’s averaged 5.4 but fluctuated significantly, peaking at 6.2 in 2022.

Example 4 
##INPUT:
Original Question: How do the operating expenses and profitability of Netflix and Disney compare in 2022?

Question Answer Pairs

What were Netflix’s operating expenses in 2022?: Netflix reported operating expenses of $25 billion in 2022.
What were Disney’s operating expenses in 2022?: I don’t know.
How do Netflix and Disney compare in terms of profitability in 2022?: Netflix had a net profit margin of 16%, while Disney had a net profit margin of 12%.

##OUTPUT: In 2022, Netflix reported operating expenses of $25 billion. In terms of profitability, Netflix had a net profit margin of 16%, compared to Disney’s 12%. No data was available for Disney’s operating expenses.


Do it for this input now


"""

answers_combination_prompt2 = ChatPromptTemplate.from_messages(
    [
        ("system", _answer_combiner_system_prompt2),
        (
            "human",
            """##INPUT:\nOriginal Question: {original_question}

Question Answer Pairs:\n{decomposed_qa_pairs}

##OUTPUT: """,
        ),
    ]
)
answers_combiner2 = answers_combination_prompt2 | llm.with_structured_output(
    CombinedAnswer
)


from state import OverallState


def reset_state_except_final_and_messages(state: OverallState):
    """
    Resets all keys in the `OverallState` dictionary except for `final_answer` and `messages`.

    Args:
        state (OverallState): The state dictionary to be modified.
    """
    for key in state.keys():
        if key not in {"final_answer", "messages"}:
            # Reset lists and strings appropriately
            if isinstance(state[key], list):
                state[key] = []
            elif isinstance(state[key], str):
                state[key] = ""


def delete_messages(state):
    messages = state["messages"]
    if len(messages) > NUM_PREV_MESSAGES:
        return {
            "messages": [RemoveMessage(id=m.id) for m in messages[:-NUM_PREV_MESSAGES]]
        }


def combine_answers(state: state.OverallState):
    """
    Combines the answers of the decomposed questions into a single final answer.
    """
    log_message("---COMBINING ALL THE DECOMPOSED ANSWERS---")

    original_question = state["question"]
    decomposed_questions = state["decomposed_questions"]
    decomposed_answers = state["decomposed_answers"]

    decomposed_qa_pairs = []
    for question, answer in zip(decomposed_questions, decomposed_answers):
        decomposed_qa_pairs.append(f"{question}: {answer}")
    decomposed_qa_pairs = "\n".join(decomposed_qa_pairs)

    combined_answer = answers_combiner.invoke(
        {
            "original_question": original_question,
            "decomposed_qa_pairs": decomposed_qa_pairs,
        }
    )
    combined_answer = combined_answer.combined_answer

    log_message(f"Combined answer: {combined_answer}")
    delete_messages(state)
    reset_state_except_final_and_messages(state)

    return {
        "final_answer": combined_answer,
        "messages": [AIMessage(role="Chatbot", content=combined_answer)],
        "clarifying_questions": [],
    }


def combine_answer_v2(state: state.OverallState):
    log_message("---COMBINING ALL THE DECOMPOSED ANSWERS---")

    original_question = state["question"]
    question_tree = state["question_tree"]
    decomposed_qa_pairs = get_questions_and_answers_by_layer(question_tree, 1)
    combined_answer = answers_combiner.invoke(
        {
            "original_question": original_question,
            "decomposed_qa_pairs": decomposed_qa_pairs,
        }
    )
    combined_answer = combined_answer.combined_answer

    log_message(f"Combined answer: {combined_answer}")
    delete_messages(state)
    reset_state_except_final_and_messages(state)

    return {
        "final_answer": combined_answer,
        "messages": [AIMessage(role="Chatbot", content=combined_answer)],
        "clarifying_questions": [],
    }


def combine_answer_v3(state: state.OverallState):
    log_message(
        "---COMBINING ALL THE DECOMPOSED ANSWERS TO ANSWER ORIGINAL QUESTION---"
    )

    """
    if(state['final_answer']):
        log_message(f"Combined answer: {state['final_answer']}")
        delete_messages(state)
        reset_state_except_final_and_messages(state)
        return {"final_answer": state['final_answer'], "messages": [AIMessage(role="Chatbot",content=combined_answer)]
                ,"clarifying_questions":[]}
    """

    # question_trees=state['question_tree_store']
    qa_pairs = "\n".join(state["qa_pairs"])

    original_question = state["question"]

    combined_answer = answers_combiner2.invoke(
        {
            "original_question": original_question,
            "decomposed_qa_pairs": qa_pairs,
        }
    )
    combined_answer = combined_answer.combined_answer

    log_message(f"Combined answer: {combined_answer}")
    delete_messages(state)
    reset_state_except_final_and_messages(state)
    return {
        "final_answer": combined_answer,
        "messages": [AIMessage(role="Chatbot", content=combined_answer)],
        "clarifying_questions": [],
    }

## SEMANTIC CACHING

class CacheSufficient(BaseModel):
    """The Construct to determine if there is an answer which fully answers the question or not"""

    index: int = Field(
        description="Gives back the index of the right answer"
    )

cache_answer_system = """
You are a question answer validation agent. 

Follow these instructions
1. Your job is to look at the given question and the set of possible answers given, and then choose which answer completely answers the question
2. Return the answer number that it comes with
3. If there is no answer which answers every part of the question well, then return -1

Here are some examples

Example 1
##INPUT: 
Question: "What was Apple's total revenue for the fiscal year 2023?"
Answers:
0.Apple's total revenue for fiscal year 2023 was $15 billion.


###OUTPUT: 0

Example 1
##INPUT:
Question: "What was Apple's total revenue for the fiscal year 2023?"
Answers:
0.Microsoft's total revenue for fiscal year 2023 was $15 billion.
1.Google's total revenue for fiscal year 2023 was $20 billion.
2.Apple's net expense on RnD is $5 billion.

###OUTPUT: -1

Now do it for this input

"""

# Modified human prompt to include child questions and answers
cache_answer_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", cache_answer_system),
        (
            "human",
            """##INPUT
Question:{question}
Answers:
{answers}

##OUTPUT: """,
        ),
    ]
)

cache_answer = cache_answer_prompt | llm.with_structured_output(
    CacheSufficient
)

def cache_retreiver_call(query):
    docs=cache_retreiver.similarity_search(query,3)
    answers_str=[f"{no}. {i.metadata['answer']}" for no,i in enumerate(docs)]
    index=cache_answer.invoke(
        {
            "question":query,
            "answers":'\n'.join(answers_str)
        }
    ).index

    if index==-1:
        return 'No'

    else:
        entry=docs[index]
        answer=entry.metadata['answer']
        final={'answer':answer}

    return final
    
