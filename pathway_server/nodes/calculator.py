"""
This module defines a Python code execution framework and a calculator agent to evaluate tasks and process answers with suggestions.

Core Components:
1. **Code Generation and Execution:**
   - `execute_task_and_get_result`: Accepts a task description, generates Python code using GPT-4's chat-based API, executes the code in a restricted environment, and returns the result. The function includes retry logic in case of errors during code generation or execution.
   - `code_generator`: A LangChain prompt template used for generating Python code via GPT-4's chat completion endpoint.

2. **Calculator Agent:**
   - **Purpose:** The `calc_agent` function evaluates a question and its associated answer using a series of operations provided by a calculator model. It either directly processes the operations or suggests further processing steps.
   - **Components:**
     - `calculator_input`: A LangChain prompt template that takes in a question and answer, invoking a calculator model to generate suggested operations.
     - `process_answer`: A function that processes the suggestions generated by the calculator and incorporates them into a final answer.

3. **Models for Structured Output:**
   - `CalculatorOutput`: A Pydantic model that stores the list of operations or instructions returned by the calculator.
   - `ProcessAnswer`: A Pydantic model that holds the final answer after applying suggestions from the calculator.

4. **Logging and Error Handling:**
   - The module includes logging functionality to track task execution, code generation, and error messages using `log_message`.
   - It also features retry logic for both code generation and execution (up to three attempts).

5. **Prompts:**
   - Utilizes LangChain's `ChatPromptTemplate` to interact with the GPT-4 model. Specific prompts are designed for generating Python code, processing calculator suggestions, and evaluating the final answer.

Dependencies:
- **LangChain** for managing prompts and invoking GPT-4's chat API.
- **Pydantic** for structured data models.
- **Internal utilities** (`log_message`, `llm`, `state`) for logging and managing execution state.

Usage:
- Call `execute_task_and_get_result(task)` to generate Python code for a specific task and return the result.
- Use `calc_agent(state)` to process answers and generate final suggestions based on calculator model outputs.
"""

from typing import Dict, List
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import state
from utils import log_message
from llm import llm
from pydantic import BaseModel, Field
import sys
from prompt import prompts

code_generator_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a Python code generator."),
        ("human", "{task}"),
    ]
)
code_generator = code_generator_prompt | llm | StrOutputParser()


def execute_task_and_get_result(task: str) -> Dict:
    """
    Takes a task description (e.g., 'average of 2, 4, and 5'), generates Python code using GPT-4's chat-based API,
    executes the code in a restricted environment, and returns the result in a human-readable format.
    """
    log_message(f"--- EXECUTE TASK: {task} ---")  # Log the task

    # Max number of retries in case of errors
    max_retries = 3

    # Variables to store previous error and code
    previous_code = ""
    previous_error = ""

    for attempt in range(1, max_retries + 1):
        log_message(f"Attempt {attempt} of code generation...")

        try:
            prompt = f"Write Python code to perform the following task and store the result in a variable called 'result': {task}"

            # If there was a previous error and code, pass them to GPT-4 to fix or improve
            if previous_error:
                prompt = (
                    f"Previous error: {previous_error}\nPrevious code:\n{previous_code}\n\n"
                    + prompt
                )
                log_message(f"Reattempting with feedback: {prompt}")

            # Send a prompt to GPT-4 to generate Python code via the chat completion endpoint
            response = code_generator.invoke({"task": prompt})

            # Extract the generated code from the API response
            code = response.strip()

            if not code:
                return {"answer": "Error: No code generated."}

            code = code.split("```python", 1)
            code = code[1].split("```", 1)
            log_message(f"Generated code: {code[0]}")

            # Store the current generated code for the next attempt (if needed)
            previous_code = code[0]

        except Exception as e:
            return {"answer": f"Error generating code: {str(e)}"}

        # Execute the generated code in a restricted environment
        safe_globals = {
            # "__builtins__": None,  # Disable all built-in functions for security
            "result": None,  # Variable to hold the result
        }

        try:
            # Execute the generated code
            exec(
                "import os;\nimport sys;\nsys.stdout = open(os.devnull, 'w')\n"
                + code[0],
                safe_globals,
            )
            sys.stdout = sys.__stdout__
            # Retrieve the result
            result = safe_globals.get("result", None)
            if result is None:
                return {"answer": "Error: No result found."}
            return {"answer": result}

        except Exception as e:
            # If there is an error in executing the code, print and handle the error
            log_message(f"Error during execution: {str(e)}")
            previous_error = str(e)  # Store the error for the next attempt

            # If it's the last attempt, return the error
            if attempt == max_retries:
                return {
                    "answer": f"Error executing the task after {max_retries} attempts: {str(e)}"
                }

            # If not the last attempt, the loop will retry automatically with new context

    # If we reach here, it means all attempts failed
    return {
        "answer": f"Sorry, the task could not be completed after {max_retries} attempts."
    }


class CalculatorOutput(BaseModel):
    """Output that we get for the query sent into the calculator"""

    caclculator_ques: List[str] = Field(
        description="Contains the list of strings which are instructions given to the calculator"
    )


calculator_system_prompt = prompts.calculator_system_prompt

calculator_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", calculator_system_prompt),
        ("human", "##INPUT:\nQuestion: {question}\nAnswer:{answer}\n\n##OUTPUT:\n"),
    ]
)
calculator_input = calculator_prompt | llm.with_structured_output(CalculatorOutput)


class ProcessAnswer(BaseModel):
    """Returns final answer after calculator suggestions"""

    answer: str = Field(
        description="Contains final answer after calculator suggestions"
    )


process_answer_system_prompt = prompts.process_answer_system_prompt

process_answer_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", process_answer_system_prompt),
        (
            "human",
            "##INPUT:\nQuestion: {question}\nAnswer:{answer}\nSuggestion:{suggestion}\n\n##OUTPUT:\n",
        ),
    ]
)
process_answer = process_answer_prompt | llm.with_structured_output(ProcessAnswer)


def calc_agent(state: state.InternalRAGState):
    question = state["original_question"]
    answer = state["answer"]
    operations = calculator_input.invoke(
        {"question": question, "answer": answer}
    ).caclculator_ques

    if operations:
        final_answer = answer

    else:
        calculator_output = []
        for operation in operations:
            calculator_output.append(execute_task_and_get_result(operation))

        suggestion_str = ""
        for operation, value in zip(operations, calculator_output):
            suggestion_str += f"{operation} - {value} \n"

        final_answer = process_answer.invoke(
            {"question": question, "answer": answer, "suggestion": suggestion_str}
        )

    return {"answer": final_answer}


# Example usage
# task = "What is year on year growth of NVIDIA?Year1:76 Year2:78 Year3:80 Year4:87"
# result = execute_task_and_get_result(task)
# print(result)  # This will print the final answer or error message
